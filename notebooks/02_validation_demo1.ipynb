{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dae4e1d5",
   "metadata": {},
   "source": [
    "(셀 1) 필요한 모든 import를 한 곳에 묶기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5445b74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install \"openai>=1.40.0\" python-dotenv pandas openpyxl numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "098249a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 1: Imports (ONLY HERE) =====\n",
    "import os, re, json\n",
    "from datetime import datetime, timezone\n",
    "from typing import Optional, Dict, List, Tuple, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16105ac0",
   "metadata": {},
   "source": [
    "(셀 2) 상수/정책/로그/.env/시간함수 “여기만” (전체 코드)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66af07a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INIT] .env loaded\n",
      "  - OPENAI_API_KEY: SET\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 2: Constants / Policies / Logging / Env =====\n",
    "\n",
    "DEBUG = True\n",
    "\n",
    "def log(layer: str, msg: str, **kwargs):\n",
    "    if not DEBUG:\n",
    "        return\n",
    "    print(f\"[{layer}] {msg}\")\n",
    "    if kwargs:\n",
    "        for k, v in kwargs.items():\n",
    "            print(f\"  - {k}: {v}\")\n",
    "\n",
    "def now_utc_iso() -> str:\n",
    "    return datetime.now(timezone.utc).replace(microsecond=0).isoformat().replace(\"+00:00\", \"Z\")\n",
    "\n",
    "# .env 로딩 (필요 시)\n",
    "load_dotenv(find_dotenv(), override=False)\n",
    "assert os.getenv(\"OPENAI_API_KEY\"), \"OPENAI_API_KEY가 .env에 없습니다.\"\n",
    "log(\"INIT\", \".env loaded\", OPENAI_API_KEY=\"SET\")\n",
    "\n",
    "# 지원 슬롯\n",
    "SLOT_NAMES = [\"electricity_usage\", \"citygas_usage\", \"water_usage\"]\n",
    "\n",
    "# 단위 토큰 표준화(키: 감지 토큰, 값: 표준 단위 문자열)\n",
    "UNIT_TOKENS = {\n",
    "    \"kwh\": \"kWh\", \"mwh\": \"MWh\", \"wh\": \"Wh\",\n",
    "    \"mj\": \"MJ\", \"gj\": \"GJ\",\n",
    "    \"m3\": \"m3\", \"㎥\": \"m3\",\n",
    "    \"tco2e\": \"tCO2e\", \"co2e\": \"tCO2e\",\n",
    "    \"kvarh\": \"kVarh\",\n",
    "}\n",
    "\n",
    "# slotName별 컬럼 패턴\n",
    "PATTERNS_BY_SLOT = {\n",
    "    \"electricity_usage\": {\n",
    "        \"date\":  [r\"\\btimestamp\\b\", r\"\\bdatetime\\b\", r\"\\bdate\\b\", r\"\\btime\\b\", \"일시\", \"시각\", \"연월일\", \"년월일\", \"일자\", \"검침일\"],\n",
    "        \"flow\":  [\"사용량\", \"전력\", \"전기사용\", \"usage\", r\"\\bconsumption\\b\", r\"\\bpower\\b\"],\n",
    "        \"cum\":   [\"누적\", \"cumulative\", \"meter\", \"계량\"],\n",
    "        \"unit\":  [r\"\\bunit\\b\", r\"\\buom\\b\", \"단위\", \"kwh\", \"mwh\", \"wh\", \"mj\", \"gj\", \"kvarh\"],\n",
    "    },\n",
    "    \"citygas_usage\": {\n",
    "        \"date\":  [r\"\\btimestamp\\b\", r\"\\bdatetime\\b\", r\"\\bdate\\b\", r\"\\btime\\b\", \"일시\", \"시각\", \"연월일\", \"년월일\", \"일자\", \"검침일\"],\n",
    "        \"flow\":  [\"사용량\", \"가스\", \"도시가스\", r\"\\bflow\\b\", r\"\\bvolume\\b\", \"usage\"],\n",
    "        \"cum\":   [\"누적\", \"cumulative\", \"meter\", \"계량\"],\n",
    "        \"unit\":  [r\"\\bunit\\b\", r\"\\buom\\b\", \"단위\", \"m3\", \"㎥\", \"gj\", \"mj\", \"tco2e\", \"co2e\"],\n",
    "    },\n",
    "    \"water_usage\": {\n",
    "        \"date\":  [r\"\\btimestamp\\b\", r\"\\bdatetime\\b\", r\"\\bdate\\b\", r\"\\btime\\b\", \"일시\", \"시각\", \"연월일\", \"년월일\", \"일자\", \"검침일\"],\n",
    "        \"flow\":  [\"사용량\", \"수도\", \"용수\", r\"\\bflow\\b\", r\"\\bvolume\\b\", \"usage\"],\n",
    "        \"cum\":   [\"누적\", \"cumulative\", \"meter\", \"계량\"],\n",
    "        \"unit\":  [r\"\\bunit\\b\", r\"\\buom\\b\", \"단위\", \"m3\", \"㎥\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "# slot별 예상 단위\n",
    "EXPECTED_UNITS_BY_SLOT = {\n",
    "    \"electricity_usage\": {\"kWh\"},\n",
    "    \"citygas_usage\": {\"m3\"},\n",
    "    \"water_usage\": {\"m3\"},\n",
    "}\n",
    "\n",
    "# 단위 토큰이 전혀 없을 때 fallback\n",
    "SLOT_DEFAULT_UNIT = {\n",
    "    \"electricity_usage\": \"kWh\",\n",
    "    \"citygas_usage\": \"m3\",\n",
    "    \"water_usage\": \"m3\",\n",
    "}\n",
    "\n",
    "# 최종 표준 컬럼명 규칙\n",
    "SLOT_OUTPUT_SCHEMA = {\n",
    "    \"electricity_usage\": {\n",
    "        \"timestamp\": \"timestamp\",\n",
    "        \"flow\": \"flow_kwh\",\n",
    "        \"cum\": None,  # 전기는 기본적으로 cum 없음\n",
    "    },\n",
    "    \"citygas_usage\": {\n",
    "        \"timestamp\": \"timestamp\",\n",
    "        \"flow\": \"flow_m3\",\n",
    "        \"cum\": None,  # 가스는 cum 필수 아님(필요 시 확장 가능)\n",
    "    },\n",
    "    \"water_usage\": {\n",
    "        \"timestamp\": \"timestamp\",\n",
    "        \"flow\": \"flow_m3\",\n",
    "        \"cum\": \"cumulative_meter_m3\",  # 수도는 cum이 있으면 core로 처리 가능\n",
    "    },\n",
    "}\n",
    "\n",
    "# 파싱률 임계치\n",
    "TS_THRESHOLD = 0.95\n",
    "NUM_THRESHOLD = 0.95\n",
    "\n",
    "# 정책\n",
    "FAIL_IF_UNIT_UNRESOLVED = False\n",
    "FAIL_IF_DUP_TS = True\n",
    "\n",
    "# LLM 옵션\n",
    "USE_LLM = False  # 운영에서는 기본 False, 필요 시 True\n",
    "\n",
    "# unit_schema label\n",
    "TIME_UNIT_LABEL = \"time\"\n",
    "UNKNOWN_UNIT_LABEL = \"-\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef8de63",
   "metadata": {},
   "source": [
    "(셀 3) 유틸 “import 없음 / 상수 재정의 없음” (전체 코드)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dadcbf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 3: Utilities (NO imports, NO constant re-definitions) =====\n",
    "\n",
    "def rule_score(colname: str, patterns: List[str]) -> int:\n",
    "    s = str(colname).lower()\n",
    "    score = 0\n",
    "    for p in patterns:\n",
    "        if p.startswith(r\"\\b\") or \"(\" in p or \"[\" in p:\n",
    "            if re.search(p, s, flags=re.IGNORECASE):\n",
    "                score += 1\n",
    "        else:\n",
    "            if p.lower() in s:\n",
    "                score += 1\n",
    "    return score\n",
    "\n",
    "def parse_rate_numeric(series: pd.Series) -> float:\n",
    "    cleaned = series.astype(str).str.replace(\",\", \"\", regex=False).str.strip()\n",
    "    parsed = pd.to_numeric(cleaned, errors=\"coerce\")\n",
    "    return float(parsed.notna().mean()) if len(parsed) else 0.0\n",
    "\n",
    "def detect_unit_from_name(colname: str) -> Optional[str]:\n",
    "    s = str(colname).lower()\n",
    "    for k, u in UNIT_TOKENS.items():\n",
    "        if k in s:\n",
    "            return u\n",
    "    return None\n",
    "\n",
    "def detect_unit_from_unit_column(unit_series: pd.Series) -> Optional[str]:\n",
    "    values = unit_series.astype(str).str.lower().dropna().tolist()\n",
    "    hits = []\n",
    "    for v in values[:500]:\n",
    "        for k, u in UNIT_TOKENS.items():\n",
    "            if k in v:\n",
    "                hits.append(u)\n",
    "    if not hits:\n",
    "        return None\n",
    "    return pd.Series(hits).mode().iloc[0]\n",
    "\n",
    "def parse_period(period_start: str, period_end: str) -> Tuple[pd.Timestamp, pd.Timestamp]:\n",
    "    ps = pd.to_datetime(period_start, errors=\"raise\").tz_localize(None)\n",
    "    pe = pd.to_datetime(period_end, errors=\"raise\").tz_localize(None)\n",
    "    if pe < ps:\n",
    "        raise ValueError(\"period_end가 period_start보다 빠릅니다.\")\n",
    "    return ps, pe\n",
    "\n",
    "def normalize_datetime_series(raw: pd.Series, period_start: pd.Timestamp) -> Tuple[pd.Series, float, Dict[str, Any], pd.Series]:\n",
    "    s = raw.astype(str).str.strip()\n",
    "\n",
    "    ts1 = pd.to_datetime(s, errors=\"coerce\")\n",
    "    if ts1.dt.tz is not None:\n",
    "        ts1 = ts1.dt.tz_localize(None)\n",
    "\n",
    "    def _fix_one(x: str) -> Optional[pd.Timestamp]:\n",
    "        if x is None: \n",
    "            return None\n",
    "        x = str(x).strip()\n",
    "        if not x:\n",
    "            return None\n",
    "\n",
    "        x2 = (x.replace(\"년\", \"/\").replace(\"월\", \"/\").replace(\"일\", \" \")\n",
    "               .replace(\"시\", \":\").replace(\"분\", \"\"))\n",
    "        x2 = x2.replace(\".\", \"/\").replace(\"-\", \"/\").replace(\",\", \" \")\n",
    "        x2 = re.sub(r\"\\s+\", \" \", x2).strip()\n",
    "\n",
    "        nums = re.findall(r\"\\d+\", x2)\n",
    "        if len(nums) < 2:\n",
    "            return None\n",
    "\n",
    "        if len(nums[0]) == 4:\n",
    "            year = int(nums[0]); idx = 1\n",
    "        else:\n",
    "            year = int(period_start.year); idx = 0\n",
    "\n",
    "        # 간단한 케이스 보정\n",
    "        try:\n",
    "            month = int(nums[idx]); day = int(nums[idx + 1])\n",
    "            hour = int(nums[idx + 2]) if len(nums) >= idx + 3 else 0\n",
    "            minute = int(nums[idx + 3]) if len(nums) >= idx + 4 else 0\n",
    "            if 0 <= hour < 24 and 0 <= minute < 60:\n",
    "                return pd.Timestamp(year=year, month=month, day=day, hour=hour, minute=minute)\n",
    "        except:\n",
    "            return None\n",
    "        return None\n",
    "\n",
    "    ts2 = ts1.copy()\n",
    "    mask_na = ts2.isna()\n",
    "    filled = 0\n",
    "    if mask_na.any():\n",
    "        fixed = s[mask_na].map(_fix_one)\n",
    "        ts2.loc[mask_na] = pd.to_datetime(fixed, errors=\"coerce\")\n",
    "        filled = int(mask_na.sum())\n",
    "\n",
    "    rate = float(ts2.notna().mean()) if len(ts2) else 0.0\n",
    "    normalized_str = ts2.dt.strftime(\"%Y/%m/%d %H:%M\")\n",
    "    debug = {\"parse_rate\": rate, \"filled_from_custom\": filled}\n",
    "    return ts2, rate, debug, normalized_str\n",
    "\n",
    "def detect_time_granularity(ts_parsed: pd.Series) -> Optional[str]:\n",
    "    ts = ts_parsed.dropna().sort_values()\n",
    "    if len(ts) < 3:\n",
    "        return None\n",
    "    deltas = ts.diff().dropna().dt.total_seconds()\n",
    "    if deltas.empty:\n",
    "        return None\n",
    "    mode_sec = float(deltas.mode().iloc[0])\n",
    "\n",
    "    if abs(mode_sec - 600) <= 60: return \"10min\"\n",
    "    if abs(mode_sec - 900) <= 60: return \"15min\"\n",
    "    if abs(mode_sec - 1800) <= 120: return \"30min\"\n",
    "    if abs(mode_sec - 3600) <= 120: return \"hourly\"\n",
    "    if abs(mode_sec - 86400) <= 3600: return \"day\"\n",
    "    if abs(mode_sec - 604800) <= 86400: return \"week\"\n",
    "    return None\n",
    "\n",
    "def granularity_to_pandas_freq(gran: str) -> Optional[str]:\n",
    "    mapping = {\"10min\": \"10min\", \"15min\": \"15min\", \"30min\": \"30min\", \"hourly\": \"h\", \"day\": \"d\"}\n",
    "    return mapping.get(gran)\n",
    "\n",
    "# ✅ (C 해결) validated_fields / unit_schema 생성은 아래 하나로 통일합니다.\n",
    "def build_output_schema(\n",
    "    df: pd.DataFrame,\n",
    "    slotName: str,\n",
    "    date_col: str,\n",
    "    flow_col: str,\n",
    "    cum_col: Optional[str],\n",
    "    resolved_flow_unit: str\n",
    ") -> Tuple[List[str], List[str], Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    - core 컬럼: timestamp, flow_*, (cum이 선택되면 cum도 core)\n",
    "    - non-core 컬럼: unit_schema는 무조건 \"-\"\n",
    "    - validated_fields: 최종 출력 컬럼명 리스트\n",
    "    - rename_map: 원본컬럼 -> 최종컬럼명\n",
    "    \"\"\"\n",
    "    schema = SLOT_OUTPUT_SCHEMA[slotName]\n",
    "    rename_map: Dict[str, str] = {}\n",
    "\n",
    "    out_ts = \"timestamp\"\n",
    "    out_flow = schema[\"flow\"]\n",
    "    out_cum = schema.get(\"cum\", None)  # water는 cumulative_meter_m3 가능\n",
    "\n",
    "    # core rename\n",
    "    rename_map[date_col] = out_ts\n",
    "    rename_map[flow_col] = out_flow\n",
    "\n",
    "    cum_is_core = False\n",
    "    if cum_col is not None and out_cum is not None:\n",
    "        rename_map[cum_col] = out_cum\n",
    "        cum_is_core = True\n",
    "\n",
    "    # validated_fields = [core...] + [others...]\n",
    "    validated_fields: List[str] = [out_ts, out_flow]\n",
    "    if cum_is_core:\n",
    "        validated_fields.append(out_cum)\n",
    "\n",
    "    # others keep original names (단, core와 이름 충돌하면 __orig)\n",
    "    reserved = set(validated_fields)\n",
    "    for c in df.columns:\n",
    "        c = str(c)\n",
    "        if c in rename_map:\n",
    "            continue\n",
    "        out_name = c\n",
    "        if out_name in reserved:\n",
    "            out_name = f\"{out_name}__orig\"\n",
    "        rename_map[c] = out_name\n",
    "        reserved.add(out_name)\n",
    "        validated_fields.append(out_name)\n",
    "\n",
    "    # unit_schema 규칙: core만 단위, 나머지는 \"-\"\n",
    "    unit_schema: List[str] = []\n",
    "    for name in validated_fields:\n",
    "        if name == out_ts:\n",
    "            unit_schema.append(TIME_UNIT_LABEL)\n",
    "        elif name == out_flow:\n",
    "            unit_schema.append(resolved_flow_unit)\n",
    "        elif cum_is_core and name == out_cum:\n",
    "            unit_schema.append(\"m3\")\n",
    "        else:\n",
    "            unit_schema.append(UNKNOWN_UNIT_LABEL)\n",
    "\n",
    "    return validated_fields, unit_schema, rename_map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc18041",
   "metadata": {},
   "source": [
    "(셀 4) strict 출력 셀 (전체 코드)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c84771b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 4: Strict Output Helpers =====\n",
    "\n",
    "def pass_output_strict(file_path: str, time_granularity: str, unit_schema: list, validated_fields: list):\n",
    "    return {\n",
    "        \"status\": \"PASS\",\n",
    "        \"file_path\": file_path,\n",
    "        \"payload\": {\n",
    "            \"time_granularity\": time_granularity,\n",
    "            \"unit_schema\": unit_schema,\n",
    "            \"validated_fields\": validated_fields\n",
    "        },\n",
    "        \"processed_at\": now_utc_iso()\n",
    "    }\n",
    "\n",
    "def fail_output_strict(file_path: str, code: str, message: str, location: str):\n",
    "    return {\n",
    "        \"status\": \"FAIL\",\n",
    "        \"error\": {\"code\": code, \"message\": message, \"location\": location},\n",
    "        \"file_path\": file_path,\n",
    "        \"processed_at\": now_utc_iso()\n",
    "    }\n",
    "\n",
    "def print_full(result: dict):\n",
    "    print(json.dumps(result, ensure_ascii=False, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba8dce8",
   "metadata": {},
   "source": [
    "Cell 5 — L0 입력 검증 (layer0_input_sanity)\n",
    "역할(쉬운 설명)\n",
    "\n",
    "“데이터프레임 검증 파이프라인에 들어오기 전에” 입력이 말이 되는지 초기 안전검사를 한다.\n",
    "\n",
    "여기서 FAIL이면 뒤 레이어(L1~L4)는 돌릴 필요가 없어서 가장 싸고 빠른 방어선임.\n",
    "\n",
    "하는 일(구체)\n",
    "\n",
    "obj가 dict인지\n",
    "\n",
    "필수키 존재 (slotName, kind, ext, period_start, period_end, dataframe)\n",
    "\n",
    "slotName이 지원 슬롯인지\n",
    "\n",
    "dataframe이 pandas.DataFrame인지, 행/열이 충분한지\n",
    "\n",
    "period_start/end가 날짜로 파싱되는지 + 역전 여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc18ceaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 5: L0 input sanity =====\n",
    "\n",
    "def layer0_input_sanity(obj: dict) -> Tuple[Optional[dict], Optional[dict]]:\n",
    "    layer = \"L0\"\n",
    "\n",
    "    if not isinstance(obj, dict):\n",
    "        log(layer, \"BAD_INPUT_TYPE\", got=str(type(obj)))\n",
    "        return None, {\"code\":\"BAD_INPUT\", \"message\":\"입력이 dict가 아닙니다.\", \"location\":\"input\"}\n",
    "\n",
    "    required = [\"slotName\", \"kind\", \"ext\", \"period_start\", \"period_end\", \"dataframe\"]\n",
    "    missing = [k for k in required if k not in obj]\n",
    "    if missing:\n",
    "        log(layer, \"MISSING_KEYS\", missing=missing)\n",
    "        return None, {\"code\":\"MISSING_KEYS\", \"message\":f\"필수 키 누락: {missing}\", \"location\":\"input\"}\n",
    "\n",
    "    slot = obj[\"slotName\"]\n",
    "    if slot not in SLOT_NAMES:\n",
    "        log(layer, \"UNKNOWN_SLOT\", slotName=slot)\n",
    "        return None, {\"code\":\"UNKNOWN_SLOT\", \"message\":f\"지원하지 않는 slotName: {slot}\", \"location\":\"input.slotName\"}\n",
    "\n",
    "    df = obj[\"dataframe\"]\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        log(layer, \"BAD_DF_TYPE\", got=str(type(df)))\n",
    "        return None, {\"code\":\"BAD_DF\", \"message\":\"dataframe이 pandas.DataFrame이 아닙니다.\", \"location\":\"input.dataframe\"}\n",
    "\n",
    "    if df.shape[0] < 1 or df.shape[1] < 2:\n",
    "        log(layer, \"NO_DATA\", shape=df.shape)\n",
    "        return None, {\"code\":\"NO_DATA\", \"message\":f\"데이터 행/열이 부족합니다. shape={df.shape}\", \"location\":\"input.dataframe\"}\n",
    "\n",
    "    try:\n",
    "        ps, pe = parse_period(obj[\"period_start\"], obj[\"period_end\"])\n",
    "    except Exception as e:\n",
    "        log(layer, \"BAD_PERIOD\", exc=type(e).__name__)\n",
    "        return None, {\"code\":\"BAD_PERIOD\", \"message\":f\"기간 파싱 실패: {type(e).__name__}\", \"location\":\"input.period_start/end\"}\n",
    "\n",
    "    log(layer, \"PASS\", slotName=slot, shape=df.shape, period_start=str(ps), period_end=str(pe))\n",
    "\n",
    "    normalized = dict(obj)\n",
    "    normalized[\"_period_start_ts\"] = ps\n",
    "    normalized[\"_period_end_ts\"] = pe\n",
    "    return normalized, None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5c7a0d",
   "metadata": {},
   "source": [
    "Cell 6 — L1 DF 정규화 (layer1_normalize_df)\n",
    "역할(쉬운 설명)\n",
    "\n",
    "각 회사 파일은 컬럼명이 “ 일시 ”, \"timestamp \"처럼 지저분할 수 있음.\n",
    "\n",
    "L1은 **컬럼명을 표준화(strip)**해서 이후 단계가 안정적으로 돌아가게 만든다.\n",
    "\n",
    "추가로 프로젝트 퀄리티를 올리기 위해:\n",
    "\n",
    "빈 컬럼명\n",
    "\n",
    "strip 후 중복 컬럼명\n",
    "을 발견하면 즉시 FAIL시킨다.\n",
    "\n",
    "왜 도움이 되나?\n",
    "\n",
    "중복 컬럼이 있으면 L2에서 date/flow 찾을 때 잘못된 컬럼 선택이 생기고,\n",
    "\n",
    "rename_map을 만들 때 충돌이 생기고,\n",
    "\n",
    "unit_schema 길이/순서가 뒤틀릴 수 있다.\n",
    "→ 그러니 L1에서 FAIL시키는 게 “품질 게이트”로 좋음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27cc3304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 6: L1 normalize DF =====\n",
    "\n",
    "def layer1_normalize_df(df: pd.DataFrame) -> Tuple[Optional[pd.DataFrame], Optional[dict]]:\n",
    "    layer = \"L1\"\n",
    "    df2 = df.copy()\n",
    "    cols = [str(c).strip() for c in df2.columns]\n",
    "\n",
    "    # 빈 컬럼명 FAIL\n",
    "    if any(c == \"\" for c in cols):\n",
    "        log(layer, \"EMPTY_COLUMN_NAME\", columns=cols)\n",
    "        return None, {\"code\":\"L1_INVALID_COLUMNS\", \"message\":\"빈 컬럼명이 존재합니다(strip 후 '').\", \"location\":\"df.columns\"}\n",
    "\n",
    "    # strip 후 중복 컬럼명 FAIL\n",
    "    if pd.Series(cols).duplicated().any():\n",
    "        log(layer, \"DUPLICATE_COLUMNS_AFTER_NORMALIZE\", columns=cols)\n",
    "        return None, {\"code\":\"L1_INVALID_COLUMNS\", \"message\":\"L1 정규화 이후 중복 컬럼명이 발생했습니다(strip 후 동일).\", \"location\":\"df.columns\"}\n",
    "\n",
    "    df2.columns = cols\n",
    "    log(layer, \"PASS\", columns=cols)\n",
    "    return df2, None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99c0bb1",
   "metadata": {},
   "source": [
    "Cell 7 — LLM 컬럼 분류 함수(“프로덕션 안전형” 최소 구현)\n",
    "역할(쉬운 설명)\n",
    "\n",
    "룰과 파싱률로도 date/flow를 못 찾는 “애매한 컬럼명” 상황에서,\n",
    "\n",
    "LLM이 “이 컬럼은 date/flow/cum/unit 중 무엇인지”를 매핑 형태로만 반환하도록 강제한다.\n",
    "\n",
    "핵심 원칙(너의 프로젝트 룰)\n",
    "\n",
    "LLM이 “설명 문장” 쓰면 안 됨 → 오직 JSON mapping만\n",
    "\n",
    "결과를 그대로 믿지 말고 → L2/L3에서 파싱률로 최종 방어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6560ddd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 7: LLM classify (safe contract) =====\n",
    "\n",
    "def llm_classify_columns_min_tokens(columns: List[str], df: pd.DataFrame, slotName: str) -> dict:\n",
    "    \"\"\"\n",
    "    반드시 아래 형태만 반환해야 함:\n",
    "    {\"mapping\": {\"colA\":\"date\", \"colB\":\"flow\", \"colC\":\"other\"...}}\n",
    "\n",
    "    - 여기서는 기본 구현을 \"안전하게 막아둠\"\n",
    "    - 팀에서 실제 OpenAI 호출을 연결하려면, 이 함수 내부만 교체하면 됨\n",
    "    \"\"\"\n",
    "    # 기본은 \"미사용\" (USE_LLM=True인데 실제 호출을 못 붙였으면 즉시 빈 mapping)\n",
    "    # => L2에서 fallback으로 이어지고, 그래도 못 찾으면 REQUIRED_FIELD_NOT_FOUND로 FAIL\n",
    "    return {\"mapping\": {}}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9fef04",
   "metadata": {},
   "source": [
    "Cell 8 — L2 컬럼 탐지(룰 → (LLM 옵션) → 파싱률 fallback)\n",
    "역할(쉬운 설명)\n",
    "\n",
    "데이터프레임에서 “날짜 컬럼(date)”과 “사용량 컬럼(flow)”을 반드시 찾아내는 단계\n",
    "\n",
    "회사마다 컬럼명이 달라서:\n",
    "\n",
    "룰 기반 점수로 후보 뽑고\n",
    "\n",
    "그래도 부족하면 LLM(옵션)\n",
    "\n",
    "마지막으로 값 형태(파싱률)로 선택한다\n",
    "\n",
    "중요한 기능(팀 질문 대비)\n",
    "\n",
    "force_llm=True면 무조건 LLM 호출 경로로 들어가도록 만들 수 있음 (테스트용)\n",
    "\n",
    "auto_llm=True는 “룰이 실패했을 때만” 자동 호출하는 운영형 옵션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80e27553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 8: L2 find columns =====\n",
    "\n",
    "def layer2_find_columns(\n",
    "    df: pd.DataFrame,\n",
    "    slotName: str,\n",
    "    topn: int = 10,\n",
    "    auto_llm: bool = True,\n",
    "    force_llm: bool = False\n",
    ") -> Tuple[Optional[str], Dict[str, Optional[str]], List[str], Optional[dict], dict]:\n",
    "\n",
    "    layer = \"L2\"\n",
    "    pats = PATTERNS_BY_SLOT[slotName]\n",
    "    cols = [str(c) for c in df.columns]\n",
    "\n",
    "    scored = []\n",
    "    for c in cols:\n",
    "        scored.append((\n",
    "            c,\n",
    "            rule_score(c, pats[\"date\"]),\n",
    "            rule_score(c, pats[\"flow\"]),\n",
    "            rule_score(c, pats[\"unit\"]),\n",
    "            rule_score(c, pats[\"cum\"])\n",
    "        ))\n",
    "\n",
    "    date_candidates = [c for c, sd, _, _, _ in sorted(scored, key=lambda x: x[1], reverse=True)[:topn] if sd > 0]\n",
    "    flow_candidates = [c for c, _, sf, _, _ in sorted(scored, key=lambda x: x[2], reverse=True)[:topn] if sf > 0]\n",
    "    cum_candidates  = [c for c, _, _, _, sc in sorted(scored, key=lambda x: x[4], reverse=True)[:topn] if sc > 0]\n",
    "    unit_cols       = [c for c, _, _, su, _ in scored if su > 0]\n",
    "\n",
    "    debug = {\n",
    "        \"scored_top10\": sorted(scored, key=lambda x: sum(x[1:]), reverse=True)[:10],\n",
    "        \"date_candidates\": date_candidates,\n",
    "        \"flow_candidates\": flow_candidates,\n",
    "        \"cum_candidates\": cum_candidates,\n",
    "        \"unit_cols\": unit_cols,\n",
    "        \"used_llm\": False,\n",
    "        \"llm_reason\": None,\n",
    "        \"llm_raw\": None\n",
    "    }\n",
    "\n",
    "    date_col = date_candidates[0] if date_candidates else None\n",
    "    flow_col = flow_candidates[0] if flow_candidates else None\n",
    "    cum_col  = cum_candidates[0] if cum_candidates else None\n",
    "\n",
    "    # (1) LLM 트리거 판단\n",
    "    need_llm = False\n",
    "    if force_llm:\n",
    "        need_llm = True\n",
    "        debug[\"llm_reason\"] = \"force_llm\"\n",
    "        log(layer, \"AUTO_LLM_TRIGGERED\", reason=\"force_llm\", USE_LLM=USE_LLM)\n",
    "    elif auto_llm and (not date_col or not flow_col):\n",
    "        # 룰이 실패했고, auto_llm 켜져 있으면 LLM을 “시도”할 수 있음\n",
    "        need_llm = True\n",
    "        debug[\"llm_reason\"] = \"rule_missing\"\n",
    "        log(layer, \"AUTO_LLM_TRIGGERED\", reason=\"rule_missing\", USE_LLM=USE_LLM)\n",
    "\n",
    "    # (2) LLM 실행(옵션)\n",
    "    if need_llm and USE_LLM:\n",
    "        debug[\"used_llm\"] = True\n",
    "        llm_res = llm_classify_columns_min_tokens(cols, df, slotName)\n",
    "        debug[\"llm_raw\"] = llm_res\n",
    "\n",
    "        mapping = (llm_res.get(\"mapping\", {}) or {})\n",
    "        date_llm = [c for c, lab in mapping.items() if lab == \"date\" and c in cols]\n",
    "        flow_llm = [c for c, lab in mapping.items() if lab == \"flow\" and c in cols]\n",
    "        cum_llm  = [c for c, lab in mapping.items() if lab == \"cum\" and c in cols]\n",
    "        unit_llm = [c for c, lab in mapping.items() if lab == \"unit\" and c in cols]\n",
    "\n",
    "        date_col = date_col or (date_llm[0] if date_llm else None)\n",
    "        flow_col = flow_col or (flow_llm[0] if flow_llm else None)\n",
    "        cum_col  = cum_col  or (cum_llm[0] if cum_llm else None)\n",
    "        unit_cols = list(set(unit_cols + unit_llm))\n",
    "\n",
    "    # (3) fallback: 값 형태로 찾기\n",
    "    if not date_col:\n",
    "        date_rates = sorted(\n",
    "            [(c, float(pd.to_datetime(df[c], errors=\"coerce\").notna().mean())) for c in cols],\n",
    "            key=lambda x: x[1], reverse=True\n",
    "        )\n",
    "        debug[\"date_fallback_top5\"] = date_rates[:5]\n",
    "        date_col = date_rates[0][0] if (date_rates and date_rates[0][1] >= TS_THRESHOLD) else None\n",
    "\n",
    "    if not flow_col:\n",
    "        val_rates = sorted([(c, parse_rate_numeric(df[c])) for c in cols], key=lambda x: x[1], reverse=True)\n",
    "        debug[\"flow_fallback_top5\"] = val_rates[:5]\n",
    "        flow_col = val_rates[0][0] if (val_rates and val_rates[0][1] >= NUM_THRESHOLD) else None\n",
    "\n",
    "    if not date_col or not flow_col:\n",
    "        return None, {\"flow\": None, \"cum\": None}, unit_cols, {\n",
    "            \"code\":\"REQUIRED_FIELD_NOT_FOUND\",\n",
    "            \"message\":\"필수 컬럼(date/flow)을 찾지 못했습니다.\",\n",
    "            \"location\":\"columns\"\n",
    "        }, debug\n",
    "\n",
    "    log(layer, \"picked\", date_col=date_col, flow_col=flow_col, cum_col=cum_col, unit_cols=unit_cols)\n",
    "    return date_col, {\"flow\": flow_col, \"cum\": cum_col}, unit_cols, None, debug\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fcf368",
   "metadata": {},
   "source": [
    "Cell 9 — L3 값 검증(파싱률/단위/해상도)\n",
    "역할(쉬운 설명)\n",
    "\n",
    "L2가 “이 컬럼이 date/flow 같아요”라고 고른 것을 진짜로 사용 가능한지 최종 확인하는 단계\n",
    "\n",
    "여기서 통과해야만 L4(기간 커버리지)로 간다.\n",
    "\n",
    "하는 일(구체)\n",
    "\n",
    "date_col의 datetime 파싱률 체크 (TS_THRESHOLD)\n",
    "\n",
    "flow_col의 숫자 파싱률 체크 (NUM_THRESHOLD)\n",
    "\n",
    "시간 간격을 보고 time_granularity 판정\n",
    "\n",
    "단위 추정(단위 컬럼 → 컬럼명 suffix → 슬롯 기본값)\n",
    "\n",
    "기대 단위와 다르면 UNIT_MISMATCH FAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "969e69c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 9: L3 validate values =====\n",
    "\n",
    "def layer3_validate_values(\n",
    "    df: pd.DataFrame,\n",
    "    slotName: str,\n",
    "    date_col: str,\n",
    "    value_cols: Dict[str, Optional[str]],\n",
    "    unit_cols: List[str],\n",
    "    period_start: pd.Timestamp\n",
    ") -> Tuple[Optional[dict], dict]:\n",
    "\n",
    "    layer = \"L3\"\n",
    "    debug: Dict[str, Any] = {}\n",
    "\n",
    "    flow_col = value_cols[\"flow\"]\n",
    "\n",
    "    ts_parsed, ts_rate, ts_dbg, ts_norm_str = normalize_datetime_series(df[date_col], period_start=period_start)\n",
    "    flow_num_rate = parse_rate_numeric(df[flow_col])\n",
    "\n",
    "    time_gran = detect_time_granularity(ts_parsed)\n",
    "\n",
    "    debug[\"ts_rate\"] = ts_rate\n",
    "    debug[\"flow_num_rate\"] = flow_num_rate\n",
    "    debug[\"time_granularity\"] = time_gran\n",
    "\n",
    "    if ts_rate < TS_THRESHOLD:\n",
    "        return {\"code\":\"TS_PARSE_LOW\", \"message\":f\"날짜 파싱률 낮음(ts_rate={ts_rate:.2f})\", \"location\":f\"col:{date_col}\"}, debug\n",
    "    if flow_num_rate < NUM_THRESHOLD:\n",
    "        return {\"code\":\"VALUE_PARSE_LOW\", \"message\":f\"숫자 파싱률 낮음(num_rate={flow_num_rate:.2f})\", \"location\":f\"col:{flow_col}\"}, debug\n",
    "    if time_gran is None:\n",
    "        return {\"code\":\"TIME_GRAIN_UNKNOWN\", \"message\":\"시간 해상도 판별 불가\", \"location\":f\"col:{date_col}\"}, debug\n",
    "\n",
    "    # 단위 결정\n",
    "    resolved_unit = None\n",
    "\n",
    "    # 1) unit 컬럼이 있으면 그 값에서 탐지\n",
    "    for uc in unit_cols or []:\n",
    "        u = detect_unit_from_unit_column(df[uc])\n",
    "        if u:\n",
    "            resolved_unit = u\n",
    "            break\n",
    "\n",
    "    # 2) flow 컬럼명에서 탐지 (Usage_kWh 같은 케이스)\n",
    "    if resolved_unit is None:\n",
    "        u = detect_unit_from_name(flow_col)\n",
    "        if u:\n",
    "            resolved_unit = u\n",
    "\n",
    "    # 3) slot 기본 단위 fallback\n",
    "    if resolved_unit is None:\n",
    "        if FAIL_IF_UNIT_UNRESOLVED:\n",
    "            return {\"code\":\"UNIT_UNRESOLVED\", \"message\":\"단위 판별 불가\", \"location\":f\"col:{flow_col}\"}, debug\n",
    "        resolved_unit = SLOT_DEFAULT_UNIT[slotName]\n",
    "\n",
    "    expected_units = EXPECTED_UNITS_BY_SLOT[slotName]\n",
    "    if resolved_unit not in expected_units:\n",
    "        return {\n",
    "            \"code\":\"UNIT_MISMATCH\",\n",
    "            \"message\":f\"단위 불일치: got={resolved_unit}, expected={list(expected_units)[0]}\",\n",
    "            \"location\":f\"col:{flow_col}\"\n",
    "        }, debug\n",
    "\n",
    "    debug[\"_ts_parsed\"] = ts_parsed\n",
    "    debug[\"resolved_unit\"] = resolved_unit\n",
    "    return None, debug\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9b9ec8",
   "metadata": {},
   "source": [
    "Cell 10 — L4 기간 커버리지(누락/중복/결측 FAIL)\n",
    "역할(쉬운 설명)\n",
    "\n",
    "“분기 보고”의 핵심은 기간 전체가 빠짐없이 채워져 있는지야.\n",
    "\n",
    "L4는 지정한 period_start~period_end에 대해:\n",
    "\n",
    "timestamp 누락\n",
    "\n",
    "timestamp 중복\n",
    "\n",
    "flow 값 결측\n",
    "을 강하게 FAIL시키는 품질 게이트임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e29e5d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 10: L4 period coverage =====\n",
    "\n",
    "def granularity_to_pandas_freq(gran: str) -> Optional[str]:\n",
    "    mapping = {\"10min\": \"10min\", \"15min\": \"15min\", \"30min\": \"30min\", \"hourly\": \"h\", \"day\": \"d\"}\n",
    "    return mapping.get(gran)\n",
    "\n",
    "def align_ts_for_compare(ts: pd.Series, gran: str) -> pd.Series:\n",
    "    if gran in (\"10min\", \"15min\", \"30min\"):\n",
    "        mins = int(gran.replace(\"min\", \"\"))\n",
    "        return ts.dt.floor(f\"{mins}min\")\n",
    "    if gran == \"hourly\":\n",
    "        return ts.dt.floor(\"h\")\n",
    "    if gran == \"day\":\n",
    "        return ts.dt.floor(\"d\")\n",
    "    return ts\n",
    "\n",
    "def layer4_validate_period_coverage(\n",
    "    df: pd.DataFrame,\n",
    "    ts_parsed: pd.Series,\n",
    "    flow_col: str,\n",
    "    period_start: pd.Timestamp,\n",
    "    period_end: pd.Timestamp,\n",
    "    granularity: str\n",
    ") -> Tuple[Optional[dict], dict]:\n",
    "\n",
    "    layer = \"L4\"\n",
    "    debug: Dict[str, Any] = {}\n",
    "\n",
    "    ts_aligned = align_ts_for_compare(ts_parsed, granularity)\n",
    "\n",
    "    mask = (ts_aligned >= period_start) & (ts_aligned <= period_end)\n",
    "    df_in = df.loc[mask].copy()\n",
    "    ts_in = ts_aligned.loc[mask]\n",
    "\n",
    "    debug[\"rows_in_period\"] = int(df_in.shape[0])\n",
    "    if df_in.shape[0] == 0:\n",
    "        return {\"code\":\"PERIOD_OUT_OF_RANGE\", \"message\":\"지정 기간 내 데이터가 없습니다.\", \"location\":\"period\"}, debug\n",
    "\n",
    "    dup_count = int(pd.Series(ts_in.dropna().values).duplicated().sum())\n",
    "    debug[\"duplicate_ts_count\"] = dup_count\n",
    "    if FAIL_IF_DUP_TS and dup_count > 0:\n",
    "        return {\"code\":\"DUPLICATE_TIMESTAMPS\", \"message\":\"기간 내 중복 timestamp 존재\", \"location\":\"timestamp\"}, debug\n",
    "\n",
    "    freq = granularity_to_pandas_freq(granularity)\n",
    "    if freq is None:\n",
    "        return {\"code\":\"TIME_GRAIN_UNKNOWN\", \"message\":\"시간 해상도 판별 불가(L4)\", \"location\":\"time_granularity\"}, debug\n",
    "\n",
    "    expected = pd.date_range(start=period_start, end=period_end, freq=freq)\n",
    "    exp_set = set(expected.tolist())\n",
    "    act_set = set(ts_in.dropna().tolist())\n",
    "\n",
    "    missing = sorted(list(exp_set - act_set))\n",
    "    if missing:\n",
    "        return {\"code\":\"PERIOD_MISSING_TIMESTAMPS\", \"message\":\"기간 내 timestamp 누락\", \"location\":\"timestamp\"}, debug\n",
    "\n",
    "    val_num = pd.to_numeric(df_in[flow_col].astype(str).str.replace(\",\", \"\", regex=False).str.strip(), errors=\"coerce\")\n",
    "    if int(val_num.isna().sum()) > 0:\n",
    "        return {\"code\":\"PERIOD_VALUE_MISSING\", \"message\":\"기간 내 flow 값 누락\", \"location\":f\"col:{flow_col}\"}, debug\n",
    "\n",
    "    log(layer, \"PASS\", rows_in_period=debug[\"rows_in_period\"])\n",
    "    return None, debug\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d74163",
   "metadata": {},
   "source": [
    "(셀 11) validate_structured_upstream (교체/전체 코드)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e062c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 11: Main validate (STRICT output only) =====\n",
    "\n",
    "# def layer0_input_sanity(obj: dict) -> Tuple[Optional[dict], Optional[dict]]:\n",
    "#     layer = \"L0\"\n",
    "\n",
    "#     if not isinstance(obj, dict):\n",
    "#         log(layer, \"BAD_INPUT_TYPE\", got=str(type(obj)))\n",
    "#         return None, {\"code\":\"BAD_INPUT\", \"message\":\"입력이 dict가 아닙니다.\", \"location\":\"input\"}\n",
    "\n",
    "#     required = [\"slotName\", \"kind\", \"ext\", \"period_start\", \"period_end\", \"dataframe\"]\n",
    "#     missing = [k for k in required if k not in obj]\n",
    "#     if missing:\n",
    "#         log(layer, \"MISSING_KEYS\", missing=missing)\n",
    "#         return None, {\"code\":\"MISSING_KEYS\", \"message\":f\"필수 키 누락: {missing}\", \"location\":\"input\"}\n",
    "\n",
    "#     slot = obj[\"slotName\"]\n",
    "#     if slot not in SLOT_NAMES:\n",
    "#         log(layer, \"UNKNOWN_SLOT\", slotName=slot)\n",
    "#         return None, {\"code\":\"UNKNOWN_SLOT\", \"message\":f\"지원하지 않는 slotName: {slot}\", \"location\":\"input.slotName\"}\n",
    "\n",
    "#     df = obj[\"dataframe\"]\n",
    "#     if not isinstance(df, pd.DataFrame):\n",
    "#         log(layer, \"BAD_DF_TYPE\", got=str(type(df)))\n",
    "#         return None, {\"code\":\"BAD_DF\", \"message\":\"dataframe이 pandas.DataFrame이 아닙니다.\", \"location\":\"input.dataframe\"}\n",
    "\n",
    "#     if df.shape[0] < 1 or df.shape[1] < 2:\n",
    "#         log(layer, \"NO_DATA\", shape=df.shape)\n",
    "#         return None, {\"code\":\"NO_DATA\", \"message\":f\"데이터 행/열이 부족합니다. shape={df.shape}\", \"location\":\"input.dataframe\"}\n",
    "\n",
    "#     try:\n",
    "#         ps, pe = parse_period(obj[\"period_start\"], obj[\"period_end\"])\n",
    "#     except Exception as e:\n",
    "#         log(layer, \"BAD_PERIOD\", exc=type(e).__name__)\n",
    "#         return None, {\"code\":\"BAD_PERIOD\", \"message\":f\"기간 파싱 실패: {type(e).__name__}\", \"location\":\"input.period_start/end\"}\n",
    "\n",
    "#     log(layer, \"PASS\", slotName=slot, shape=df.shape, period_start=str(ps), period_end=str(pe))\n",
    "\n",
    "#     normalized = dict(obj)\n",
    "#     normalized[\"_period_start_ts\"] = ps\n",
    "#     normalized[\"_period_end_ts\"] = pe\n",
    "#     return normalized, None\n",
    "\n",
    "\n",
    "# def layer1_normalize_df(df: pd.DataFrame) -> Tuple[Optional[pd.DataFrame], Optional[dict]]:\n",
    "#     \"\"\"\n",
    "#     L1: 컬럼명 strip + (중복/빈 컬럼명) 감지 시 FAIL\n",
    "#     \"\"\"\n",
    "#     layer = \"L1\"\n",
    "#     df2 = df.copy()\n",
    "#     cols = [str(c).strip() for c in df2.columns]\n",
    "\n",
    "#     # 빈 컬럼명 체크\n",
    "#     if any(c == \"\" for c in cols):\n",
    "#         log(layer, \"EMPTY_COLUMN_NAME\", columns=cols)\n",
    "#         return None, {\"code\":\"L1_INVALID_COLUMNS\", \"message\":\"빈 컬럼명이 존재합니다(strip 후 '').\", \"location\":\"df.columns\"}\n",
    "\n",
    "#     # 중복 컬럼명 체크\n",
    "#     if pd.Series(cols).duplicated().any():\n",
    "#         log(layer, \"DUPLICATE_COLUMNS_AFTER_NORMALIZE\", columns=cols)\n",
    "#         return None, {\"code\":\"L1_INVALID_COLUMNS\", \"message\":\"L1 정규화 이후 중복 컬럼명이 발생했습니다(strip 후 동일).\", \"location\":\"df.columns\"}\n",
    "\n",
    "#     df2.columns = cols\n",
    "#     log(layer, \"PASS\", columns=cols)\n",
    "#     return df2, None\n",
    "\n",
    "\n",
    "# def layer2_find_columns(df: pd.DataFrame, slotName: str, topn: int = 10) -> Tuple[Optional[str], Dict[str, Optional[str]], List[str], Optional[dict], dict]:\n",
    "#     layer = \"L2\"\n",
    "#     pats = PATTERNS_BY_SLOT[slotName]\n",
    "#     cols = [str(c) for c in df.columns]\n",
    "\n",
    "#     scored = []\n",
    "#     for c in cols:\n",
    "#         scored.append((\n",
    "#             c,\n",
    "#             rule_score(c, pats[\"date\"]),\n",
    "#             rule_score(c, pats[\"flow\"]),\n",
    "#             rule_score(c, pats[\"unit\"]),\n",
    "#             rule_score(c, pats[\"cum\"])\n",
    "#         ))\n",
    "\n",
    "#     date_candidates = [c for c, sd, _, _, _ in sorted(scored, key=lambda x: x[1], reverse=True)[:topn] if sd > 0]\n",
    "#     flow_candidates = [c for c, _, sf, _, _ in sorted(scored, key=lambda x: x[2], reverse=True)[:topn] if sf > 0]\n",
    "#     cum_candidates  = [c for c, _, _, _, sc in sorted(scored, key=lambda x: x[4], reverse=True)[:topn] if sc > 0]\n",
    "#     unit_cols       = [c for c, _, _, su, _ in scored if su > 0]\n",
    "\n",
    "#     debug = {\n",
    "#         \"scored_top10\": sorted(scored, key=lambda x: sum(x[1:]), reverse=True)[:10],\n",
    "#         \"date_candidates\": date_candidates,\n",
    "#         \"flow_candidates\": flow_candidates,\n",
    "#         \"cum_candidates\": cum_candidates,\n",
    "#         \"unit_cols\": unit_cols,\n",
    "#         \"used_llm\": False,\n",
    "#     }\n",
    "\n",
    "#     date_col = date_candidates[0] if date_candidates else None\n",
    "#     flow_col = flow_candidates[0] if flow_candidates else None\n",
    "#     cum_col  = cum_candidates[0] if cum_candidates else None\n",
    "\n",
    "#     # 룰 부족 시: fallback (LLM은 여기서 쓰려면 별도 llm_classify...를 연결하면 됨)\n",
    "#     if not date_col:\n",
    "#         date_rates = sorted(\n",
    "#             [(c, float(pd.to_datetime(df[c], errors=\"coerce\").notna().mean())) for c in cols],\n",
    "#             key=lambda x: x[1], reverse=True\n",
    "#         )\n",
    "#         debug[\"date_fallback_top5\"] = date_rates[:5]\n",
    "#         date_col = date_rates[0][0] if (date_rates and date_rates[0][1] >= TS_THRESHOLD) else None\n",
    "\n",
    "#     if not flow_col:\n",
    "#         val_rates = sorted([(c, parse_rate_numeric(df[c])) for c in cols], key=lambda x: x[1], reverse=True)\n",
    "#         debug[\"flow_fallback_top5\"] = val_rates[:5]\n",
    "#         flow_col = val_rates[0][0] if (val_rates and val_rates[0][1] >= NUM_THRESHOLD) else None\n",
    "\n",
    "#     if not date_col or not flow_col:\n",
    "#         return None, {\"flow\": None, \"cum\": None}, unit_cols, {\n",
    "#             \"code\":\"REQUIRED_FIELD_NOT_FOUND\",\n",
    "#             \"message\":\"필수 컬럼(date/flow)을 찾지 못했습니다.\",\n",
    "#             \"location\":\"columns\"\n",
    "#         }, debug\n",
    "\n",
    "#     log(layer, \"picked\", date_col=date_col, flow_col=flow_col, cum_col=cum_col, unit_cols=unit_cols)\n",
    "#     return date_col, {\"flow\": flow_col, \"cum\": cum_col}, unit_cols, None, debug\n",
    "\n",
    "\n",
    "# def layer3_validate_values(\n",
    "#     df: pd.DataFrame,\n",
    "#     slotName: str,\n",
    "#     date_col: str,\n",
    "#     value_cols: Dict[str, Optional[str]],\n",
    "#     unit_cols: List[str],\n",
    "#     period_start: pd.Timestamp\n",
    "# ) -> Tuple[Optional[dict], dict]:\n",
    "#     layer = \"L3\"\n",
    "#     debug: Dict[str, Any] = {}\n",
    "\n",
    "#     flow_col = value_cols[\"flow\"]\n",
    "#     cum_col  = value_cols.get(\"cum\")\n",
    "\n",
    "#     ts_parsed, ts_rate, ts_dbg, ts_norm_str = normalize_datetime_series(df[date_col], period_start=period_start)\n",
    "#     flow_num_rate = parse_rate_numeric(df[flow_col])\n",
    "\n",
    "#     debug[\"ts_rate\"] = ts_rate\n",
    "#     debug[\"flow_num_rate\"] = flow_num_rate\n",
    "#     debug[\"time_granularity\"] = detect_time_granularity(ts_parsed)\n",
    "\n",
    "#     if ts_rate < TS_THRESHOLD:\n",
    "#         return {\"code\":\"TS_PARSE_LOW\", \"message\":f\"날짜 파싱률이 낮습니다(ts_rate={ts_rate:.2f}).\", \"location\":f\"col:{date_col}\"}, debug\n",
    "#     if flow_num_rate < NUM_THRESHOLD:\n",
    "#         return {\"code\":\"VALUE_PARSE_LOW\", \"message\":f\"flow 숫자 파싱률이 낮습니다(num_rate={flow_num_rate:.2f}).\", \"location\":f\"col:{flow_col}\"}, debug\n",
    "#     if debug[\"time_granularity\"] is None:\n",
    "#         return {\"code\":\"TIME_GRAIN_UNKNOWN\", \"message\":\"시간 해상도를 판별할 수 없습니다.\", \"location\":f\"col:{date_col}\"}, debug\n",
    "\n",
    "#     # 단위 결정: unit_col -> flow_col_name -> slot_default\n",
    "#     resolved_unit = None\n",
    "#     for uc in unit_cols or []:\n",
    "#         u = detect_unit_from_unit_column(df[uc])\n",
    "#         if u:\n",
    "#             resolved_unit = u\n",
    "#             break\n",
    "#     if resolved_unit is None:\n",
    "#         u = detect_unit_from_name(flow_col)\n",
    "#         if u:\n",
    "#             resolved_unit = u\n",
    "#     if resolved_unit is None:\n",
    "#         if FAIL_IF_UNIT_UNRESOLVED:\n",
    "#             return {\"code\":\"UNIT_UNRESOLVED\", \"message\":\"단위를 판별할 수 없습니다.\", \"location\":f\"col:{flow_col}\"}, debug\n",
    "#         resolved_unit = SLOT_DEFAULT_UNIT[slotName]\n",
    "\n",
    "#     # 단위 불일치 FAIL\n",
    "#     expected_units = EXPECTED_UNITS_BY_SLOT[slotName]\n",
    "#     if resolved_unit not in expected_units:\n",
    "#         return {\"code\":\"UNIT_MISMATCH\", \"message\":f\"단위 불일치: got={resolved_unit}, expected={list(expected_units)[0]}\", \"location\":f\"col:{flow_col}\"}, debug\n",
    "\n",
    "#     debug[\"_ts_parsed\"] = ts_parsed\n",
    "#     debug[\"resolved_unit\"] = resolved_unit\n",
    "#     return None, debug\n",
    "\n",
    "\n",
    "# def align_ts_for_compare(ts: pd.Series, gran: str) -> pd.Series:\n",
    "#     if gran in (\"10min\", \"15min\", \"30min\"):\n",
    "#         mins = int(gran.replace(\"min\", \"\"))\n",
    "#         return ts.dt.floor(f\"{mins}min\")\n",
    "#     if gran == \"hourly\":\n",
    "#         return ts.dt.floor(\"h\")\n",
    "#     if gran == \"day\":\n",
    "#         return ts.dt.floor(\"d\")\n",
    "#     return ts\n",
    "\n",
    "\n",
    "# def layer4_validate_period_coverage(\n",
    "#     df: pd.DataFrame,\n",
    "#     ts_parsed: pd.Series,\n",
    "#     flow_col: str,\n",
    "#     period_start: pd.Timestamp,\n",
    "#     period_end: pd.Timestamp,\n",
    "#     granularity: str\n",
    "# ) -> Tuple[Optional[dict], dict]:\n",
    "#     layer = \"L4\"\n",
    "#     debug: Dict[str, Any] = {}\n",
    "\n",
    "#     ts_aligned = align_ts_for_compare(ts_parsed, granularity)\n",
    "#     mask = (ts_aligned >= period_start) & (ts_aligned <= period_end)\n",
    "#     df_in = df.loc[mask].copy()\n",
    "#     ts_in = ts_aligned.loc[mask]\n",
    "\n",
    "#     debug[\"rows_in_period\"] = int(df_in.shape[0])\n",
    "#     if df_in.shape[0] == 0:\n",
    "#         return {\"code\":\"PERIOD_OUT_OF_RANGE\", \"message\":\"지정 기간 내 데이터가 없습니다.\", \"location\":\"period\"}, debug\n",
    "\n",
    "#     dup_count = int(pd.Series(ts_in.dropna().values).duplicated().sum())\n",
    "#     debug[\"duplicate_ts_count\"] = dup_count\n",
    "#     if FAIL_IF_DUP_TS and dup_count > 0:\n",
    "#         return {\"code\":\"DUPLICATE_TIMESTAMPS\", \"message\":\"기간 내 중복 timestamp가 존재합니다.\", \"location\":\"timestamp\"}, debug\n",
    "\n",
    "#     freq = granularity_to_pandas_freq(granularity)\n",
    "#     if freq is None:\n",
    "#         return {\"code\":\"TIME_GRAIN_UNKNOWN\", \"message\":\"시간 해상도를 판별할 수 없습니다(L4).\", \"location\":\"time_granularity\"}, debug\n",
    "\n",
    "#     expected = pd.date_range(start=period_start, end=period_end, freq=freq)\n",
    "#     exp_set = set(expected.tolist())\n",
    "#     act_set = set(ts_in.dropna().tolist())\n",
    "#     missing = sorted(list(exp_set - act_set))\n",
    "#     if missing:\n",
    "#         return {\"code\":\"PERIOD_MISSING_TIMESTAMPS\", \"message\":\"기간 내 timestamp 누락\", \"location\":\"timestamp\"}, debug\n",
    "\n",
    "#     val_num = pd.to_numeric(df_in[flow_col].astype(str).str.replace(\",\", \"\", regex=False).str.strip(), errors=\"coerce\")\n",
    "#     if int(val_num.isna().sum()) > 0:\n",
    "#         return {\"code\":\"PERIOD_VALUE_MISSING\", \"message\":\"기간 내 flow 값 누락\", \"location\":f\"col:{flow_col}\"}, debug\n",
    "\n",
    "#     log(layer, \"PASS\", rows_in_period=debug[\"rows_in_period\"])\n",
    "#     return None, debug\n",
    "\n",
    "\n",
    "def validate_structured_upstream(obj: dict, file_path: str = \"upstream.xlsx\"):\n",
    "    log(\"MAIN\", \"start\", slotName=obj.get(\"slotName\"), file_path=file_path)\n",
    "\n",
    "    # L0\n",
    "    norm, err0 = layer0_input_sanity(obj)\n",
    "    if err0:\n",
    "        return fail_output_strict(file_path, err0[\"code\"], err0[\"message\"], err0[\"location\"])\n",
    "\n",
    "    slotName = norm[\"slotName\"]\n",
    "    df_raw = norm[\"dataframe\"]\n",
    "    ps, pe = norm[\"_period_start_ts\"], norm[\"_period_end_ts\"]\n",
    "\n",
    "    # L1\n",
    "    df, err1 = layer1_normalize_df(df_raw)\n",
    "    if err1:\n",
    "        return fail_output_strict(file_path, err1[\"code\"], err1[\"message\"], err1[\"location\"])\n",
    "\n",
    "    # L2\n",
    "    date_col, value_cols, unit_cols, err2, _ = layer2_find_columns(df, slotName=slotName)\n",
    "    if err2:\n",
    "        return fail_output_strict(file_path, err2[\"code\"], err2[\"message\"], err2[\"location\"])\n",
    "\n",
    "    # L3\n",
    "    err3, dbg3 = layer3_validate_values(df, slotName, date_col, value_cols, unit_cols, ps)\n",
    "    if err3:\n",
    "        return fail_output_strict(file_path, err3[\"code\"], err3[\"message\"], err3[\"location\"])\n",
    "\n",
    "    # L4\n",
    "    err4, _ = layer4_validate_period_coverage(df, dbg3[\"_ts_parsed\"], value_cols[\"flow\"], ps, pe, dbg3[\"time_granularity\"])\n",
    "    if err4:\n",
    "        return fail_output_strict(file_path, err4[\"code\"], err4[\"message\"], err4[\"location\"])\n",
    "\n",
    "    # 여기서 output 스키마/단위 스키마를 \"하나의 함수\"로 통일 생성\n",
    "    validated_fields, unit_schema, rename_map = build_output_schema(\n",
    "        df=df,\n",
    "        slotName=slotName,\n",
    "        date_col=date_col,\n",
    "        flow_col=value_cols[\"flow\"],\n",
    "        cum_col=value_cols.get(\"cum\"),\n",
    "        resolved_flow_unit=dbg3[\"resolved_unit\"]\n",
    "    )\n",
    "\n",
    "    payload_time_gran = dbg3[\"time_granularity\"]\n",
    "    return pass_output_strict(file_path, payload_time_gran, unit_schema, validated_fields)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e24e68c",
   "metadata": {},
   "source": [
    "테스트 셀들(12~19)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079d699a",
   "metadata": {},
   "source": [
    "Cell 12 — 테스트 데이터 생성기(현실성 + 규모)\n",
    "역할\n",
    "\n",
    "전기(15분, 8832행), 가스/수도(시간, 2208행) 같은 현실적 규모로 df를 만든다.\n",
    "\n",
    "“파일 I/O 없이도” 파이프라인 검증 가능."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c7bd1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 12: Test data generators =====\n",
    "\n",
    "def make_ts_range(period_start: str, period_end: str, freq: str) -> pd.DatetimeIndex:\n",
    "    ps = pd.to_datetime(period_start)\n",
    "    pe = pd.to_datetime(period_end)\n",
    "    return pd.date_range(ps, pe, freq=freq)\n",
    "\n",
    "def gen_electricity_df(period_start: str, period_end: str) -> pd.DataFrame:\n",
    "    ts = make_ts_range(period_start, period_end, \"15min\")\n",
    "    n = len(ts)\n",
    "    df = pd.DataFrame({\n",
    "        \"date\": ts,\n",
    "        \"Usage_kWh\": np.round(np.random.uniform(50, 180, n), 3),\n",
    "        \"Lagging_Current_Reactive.Power_kVarh\": np.round(np.random.uniform(0, 30, n), 3),\n",
    "        \"Leading_Current_Reactive_Power_kVarh\": np.round(np.random.uniform(0, 30, n), 3),\n",
    "        \"Lagging_Current_Power_Factor\": np.round(np.random.uniform(0.7, 1.0, n), 3),\n",
    "        \"Leading_Current_Power_Factor\": np.round(np.random.uniform(0.7, 1.0, n), 3),\n",
    "    })\n",
    "    return df\n",
    "\n",
    "def gen_water_df(period_start: str, period_end: str) -> pd.DataFrame:\n",
    "    ts = make_ts_range(period_start, period_end, \"h\")\n",
    "    n = len(ts)\n",
    "    flow = np.round(np.random.uniform(5, 40, n), 3)\n",
    "    cum = np.round(np.cumsum(flow), 3)\n",
    "    df = pd.DataFrame({\n",
    "        \"timestamp\": ts,\n",
    "        \"flow_m3\": flow,\n",
    "        \"cumulative_meter_m3\": cum\n",
    "    })\n",
    "    return df\n",
    "\n",
    "def gen_citygas_df(period_start: str, period_end: str) -> pd.DataFrame:\n",
    "    ts = make_ts_range(period_start, period_end, \"h\")\n",
    "    n = len(ts)\n",
    "    flow = np.round(np.random.uniform(10, 60, n), 3)\n",
    "    calorific = np.round(np.random.uniform(38, 43, n), 3)  # MJ/m3 근사\n",
    "    energy = np.round(flow * calorific, 3)                  # MJ\n",
    "    co2e = np.round(energy * 0.000056, 6)                   # 임의 계수(테스트용)\n",
    "    df = pd.DataFrame({\n",
    "        \"timestamp\": ts,\n",
    "        \"flow_m3\": flow,\n",
    "        \"calorific_MJ_per_m3\": calorific,\n",
    "        \"energy_MJ\": energy,\n",
    "        \"CO2e_t\": co2e,\n",
    "    })\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40aace92",
   "metadata": {},
   "source": [
    "Cell 13 — PASS 테스트 3종(전기/수도/가스)\n",
    "역할\n",
    "\n",
    "“실제 운영 성공 케이스” 3개를 한 번에 보여줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "532f60f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== [PASS] 전기요금 ===\n",
      "[MAIN] start\n",
      "  - slotName: electricity_usage\n",
      "  - file_path: 성광벤드_전기요금_검증용_정형증빙.xlsx\n",
      "[L0] PASS\n",
      "  - slotName: electricity_usage\n",
      "  - shape: (8753, 6)\n",
      "  - period_start: 2025-10-01 00:00:00\n",
      "  - period_end: 2025-12-31 04:00:00\n",
      "[L1] PASS\n",
      "  - columns: ['date', 'Usage_kWh', 'Lagging_Current_Reactive.Power_kVarh', 'Leading_Current_Reactive_Power_kVarh', 'Lagging_Current_Power_Factor', 'Leading_Current_Power_Factor']\n",
      "[L2] picked\n",
      "  - date_col: date\n",
      "  - flow_col: Usage_kWh\n",
      "  - cum_col: None\n",
      "  - unit_cols: ['Usage_kWh', 'Lagging_Current_Reactive.Power_kVarh', 'Leading_Current_Reactive_Power_kVarh']\n",
      "[L4] PASS\n",
      "  - rows_in_period: 8753\n",
      "{\n",
      "  \"status\": \"PASS\",\n",
      "  \"file_path\": \"성광벤드_전기요금_검증용_정형증빙.xlsx\",\n",
      "  \"payload\": {\n",
      "    \"time_granularity\": \"15min\",\n",
      "    \"unit_schema\": [\n",
      "      \"time\",\n",
      "      \"kWh\",\n",
      "      \"-\",\n",
      "      \"-\",\n",
      "      \"-\",\n",
      "      \"-\"\n",
      "    ],\n",
      "    \"validated_fields\": [\n",
      "      \"timestamp\",\n",
      "      \"flow_kwh\",\n",
      "      \"Lagging_Current_Reactive.Power_kVarh\",\n",
      "      \"Leading_Current_Reactive_Power_kVarh\",\n",
      "      \"Lagging_Current_Power_Factor\",\n",
      "      \"Leading_Current_Power_Factor\"\n",
      "    ]\n",
      "  },\n",
      "  \"processed_at\": \"2026-01-21T00:29:35Z\"\n",
      "}\n",
      "\n",
      "=== [PASS] 수도요금 ===\n",
      "[MAIN] start\n",
      "  - slotName: water_usage\n",
      "  - file_path: 성광벤드_수도요금_검증용_정형증빙.xlsx\n",
      "[L0] PASS\n",
      "  - slotName: water_usage\n",
      "  - shape: (2189, 3)\n",
      "  - period_start: 2025-10-01 00:00:00\n",
      "  - period_end: 2025-12-31 04:00:00\n",
      "[L1] PASS\n",
      "  - columns: ['timestamp', 'flow_m3', 'cumulative_meter_m3']\n",
      "[L2] AUTO_LLM_TRIGGERED\n",
      "  - reason: rule_missing\n",
      "  - USE_LLM: False\n",
      "[L2] picked\n",
      "  - date_col: timestamp\n",
      "  - flow_col: flow_m3\n",
      "  - cum_col: cumulative_meter_m3\n",
      "  - unit_cols: ['flow_m3', 'cumulative_meter_m3']\n",
      "[L4] PASS\n",
      "  - rows_in_period: 2189\n",
      "{\n",
      "  \"status\": \"PASS\",\n",
      "  \"file_path\": \"성광벤드_수도요금_검증용_정형증빙.xlsx\",\n",
      "  \"payload\": {\n",
      "    \"time_granularity\": \"hourly\",\n",
      "    \"unit_schema\": [\n",
      "      \"time\",\n",
      "      \"m3\",\n",
      "      \"m3\"\n",
      "    ],\n",
      "    \"validated_fields\": [\n",
      "      \"timestamp\",\n",
      "      \"flow_m3\",\n",
      "      \"cumulative_meter_m3\"\n",
      "    ]\n",
      "  },\n",
      "  \"processed_at\": \"2026-01-21T00:29:35Z\"\n",
      "}\n",
      "\n",
      "=== [PASS] 도시가스요금 ===\n",
      "[MAIN] start\n",
      "  - slotName: citygas_usage\n",
      "  - file_path: 성광벤드_도시가스요금_검증용_정형증빙.xlsx\n",
      "[L0] PASS\n",
      "  - slotName: citygas_usage\n",
      "  - shape: (2189, 5)\n",
      "  - period_start: 2025-10-01 00:00:00\n",
      "  - period_end: 2025-12-31 04:00:00\n",
      "[L1] PASS\n",
      "  - columns: ['timestamp', 'flow_m3', 'calorific_MJ_per_m3', 'energy_MJ', 'CO2e_t']\n",
      "[L2] AUTO_LLM_TRIGGERED\n",
      "  - reason: rule_missing\n",
      "  - USE_LLM: False\n",
      "[L2] picked\n",
      "  - date_col: timestamp\n",
      "  - flow_col: flow_m3\n",
      "  - cum_col: None\n",
      "  - unit_cols: ['flow_m3', 'calorific_MJ_per_m3', 'energy_MJ', 'CO2e_t']\n",
      "[L4] PASS\n",
      "  - rows_in_period: 2189\n",
      "{\n",
      "  \"status\": \"PASS\",\n",
      "  \"file_path\": \"성광벤드_도시가스요금_검증용_정형증빙.xlsx\",\n",
      "  \"payload\": {\n",
      "    \"time_granularity\": \"hourly\",\n",
      "    \"unit_schema\": [\n",
      "      \"time\",\n",
      "      \"m3\",\n",
      "      \"-\",\n",
      "      \"-\",\n",
      "      \"-\"\n",
      "    ],\n",
      "    \"validated_fields\": [\n",
      "      \"timestamp\",\n",
      "      \"flow_m3\",\n",
      "      \"calorific_MJ_per_m3\",\n",
      "      \"energy_MJ\",\n",
      "      \"CO2e_t\"\n",
      "    ]\n",
      "  },\n",
      "  \"processed_at\": \"2026-01-21T00:29:35Z\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 13: PASS tests (3 slots) =====\n",
    "\n",
    "PERIOD_START = \"2025-10-01T00:00:00\"\n",
    "PERIOD_END   = \"2025-12-31T04:00:00\"\n",
    "\n",
    "# (1) 전기 PASS\n",
    "obj_e = {\n",
    "    \"slotName\": \"electricity_usage\",\n",
    "    \"kind\": \"EXCEL\",\n",
    "    \"ext\": \"xlsx\",\n",
    "    \"period_start\": PERIOD_START,\n",
    "    \"period_end\": PERIOD_END,\n",
    "    \"dataframe\": gen_electricity_df(PERIOD_START, PERIOD_END)\n",
    "}\n",
    "print(\"=== [PASS] 전기요금 ===\")\n",
    "res = validate_structured_upstream(obj_e, file_path=\"성광벤드_전기요금_검증용_정형증빙.xlsx\")\n",
    "print_full(res)\n",
    "\n",
    "# (2) 수도 PASS\n",
    "obj_w = {\n",
    "    \"slotName\": \"water_usage\",\n",
    "    \"kind\": \"EXCEL\",\n",
    "    \"ext\": \"xlsx\",\n",
    "    \"period_start\": PERIOD_START,\n",
    "    \"period_end\": PERIOD_END,\n",
    "    \"dataframe\": gen_water_df(PERIOD_START, PERIOD_END)\n",
    "}\n",
    "print(\"\\n=== [PASS] 수도요금 ===\")\n",
    "res = validate_structured_upstream(obj_w, file_path=\"성광벤드_수도요금_검증용_정형증빙.xlsx\")\n",
    "print_full(res)\n",
    "\n",
    "# (3) 가스 PASS\n",
    "obj_g = {\n",
    "    \"slotName\": \"citygas_usage\",\n",
    "    \"kind\": \"EXCEL\",\n",
    "    \"ext\": \"xlsx\",\n",
    "    \"period_start\": PERIOD_START,\n",
    "    \"period_end\": PERIOD_END,\n",
    "    \"dataframe\": gen_citygas_df(PERIOD_START, PERIOD_END)\n",
    "}\n",
    "print(\"\\n=== [PASS] 도시가스요금 ===\")\n",
    "res = validate_structured_upstream(obj_g, file_path=\"성광벤드_도시가스요금_검증용_정형증빙.xlsx\")\n",
    "print_full(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403be530",
   "metadata": {},
   "source": [
    "Cell 14 — FAIL(L0) 테스트 2종\n",
    "역할\n",
    "\n",
    "입력 단계에서 FAIL이 제대로 발생하는지 증명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0e01a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== [FAIL 기대] L0 - MISSING_KEYS ===\n",
      "[MAIN] start\n",
      "  - slotName: None\n",
      "  - file_path: L0_missing_keys.xlsx\n",
      "[L0] MISSING_KEYS\n",
      "  - missing: ['slotName']\n",
      "{\n",
      "  \"status\": \"FAIL\",\n",
      "  \"error\": {\n",
      "    \"code\": \"MISSING_KEYS\",\n",
      "    \"message\": \"필수 키 누락: ['slotName']\",\n",
      "    \"location\": \"input\"\n",
      "  },\n",
      "  \"file_path\": \"L0_missing_keys.xlsx\",\n",
      "  \"processed_at\": \"2026-01-21T00:29:36Z\"\n",
      "}\n",
      "\n",
      "=== [FAIL 기대] L0 - BAD_DF ===\n",
      "[MAIN] start\n",
      "  - slotName: electricity_usage\n",
      "  - file_path: L0_bad_df.xlsx\n",
      "[L0] BAD_DF_TYPE\n",
      "  - got: <class 'str'>\n",
      "{\n",
      "  \"status\": \"FAIL\",\n",
      "  \"error\": {\n",
      "    \"code\": \"BAD_DF\",\n",
      "    \"message\": \"dataframe이 pandas.DataFrame이 아닙니다.\",\n",
      "    \"location\": \"input.dataframe\"\n",
      "  },\n",
      "  \"file_path\": \"L0_bad_df.xlsx\",\n",
      "  \"processed_at\": \"2026-01-21T00:29:36Z\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 14: FAIL tests - L0 =====\n",
    "\n",
    "print(\"=== [FAIL 기대] L0 - MISSING_KEYS ===\")\n",
    "obj = {\"kind\":\"EXCEL\",\"ext\":\"xlsx\",\"period_start\":PERIOD_START,\"period_end\":PERIOD_END,\"dataframe\":pd.DataFrame({\"a\":[1],\"b\":[2]})}\n",
    "print_full(validate_structured_upstream(obj, file_path=\"L0_missing_keys.xlsx\"))\n",
    "\n",
    "print(\"\\n=== [FAIL 기대] L0 - BAD_DF ===\")\n",
    "obj = {\"slotName\":\"electricity_usage\",\"kind\":\"EXCEL\",\"ext\":\"xlsx\",\"period_start\":PERIOD_START,\"period_end\":PERIOD_END,\"dataframe\":\"NOT_DF\"}\n",
    "print_full(validate_structured_upstream(obj, file_path=\"L0_bad_df.xlsx\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff89f19",
   "metadata": {},
   "source": [
    "Cell 15 — FAIL(L1) 중복/빈 컬럼명\n",
    "역할\n",
    "\n",
    "L1 품질 게이트(중복/빈 컬럼명)가 실제로 FAIL을 만드는지 증명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "febedf2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== [FAIL 기대] L1 - 중복 컬럼명(strip 후 동일) ===\n",
      "[MAIN] start\n",
      "  - slotName: electricity_usage\n",
      "  - file_path: L1_dup_cols.xlsx\n",
      "[L0] PASS\n",
      "  - slotName: electricity_usage\n",
      "  - shape: (10, 3)\n",
      "  - period_start: 2025-10-01 00:00:00\n",
      "  - period_end: 2025-12-31 04:00:00\n",
      "[L1] DUPLICATE_COLUMNS_AFTER_NORMALIZE\n",
      "  - columns: ['A', 'A', 'B']\n",
      "{\n",
      "  \"status\": \"FAIL\",\n",
      "  \"error\": {\n",
      "    \"code\": \"L1_INVALID_COLUMNS\",\n",
      "    \"message\": \"L1 정규화 이후 중복 컬럼명이 발생했습니다(strip 후 동일).\",\n",
      "    \"location\": \"df.columns\"\n",
      "  },\n",
      "  \"file_path\": \"L1_dup_cols.xlsx\",\n",
      "  \"processed_at\": \"2026-01-21T00:29:37Z\"\n",
      "}\n",
      "\n",
      "=== [FAIL 기대] L1 - 빈 컬럼명 ===\n",
      "[MAIN] start\n",
      "  - slotName: electricity_usage\n",
      "  - file_path: L1_empty_col.xlsx\n",
      "[L0] PASS\n",
      "  - slotName: electricity_usage\n",
      "  - shape: (10, 2)\n",
      "  - period_start: 2025-10-01 00:00:00\n",
      "  - period_end: 2025-12-31 04:00:00\n",
      "[L1] EMPTY_COLUMN_NAME\n",
      "  - columns: ['', 'B']\n",
      "{\n",
      "  \"status\": \"FAIL\",\n",
      "  \"error\": {\n",
      "    \"code\": \"L1_INVALID_COLUMNS\",\n",
      "    \"message\": \"빈 컬럼명이 존재합니다(strip 후 '').\",\n",
      "    \"location\": \"df.columns\"\n",
      "  },\n",
      "  \"file_path\": \"L1_empty_col.xlsx\",\n",
      "  \"processed_at\": \"2026-01-21T00:29:37Z\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 15: FAIL tests - L1 =====\n",
    "\n",
    "print(\"=== [FAIL 기대] L1 - 중복 컬럼명(strip 후 동일) ===\")\n",
    "df = pd.DataFrame({\"A\":[1]*10, \" A \":[2]*10, \"B\":[3]*10})\n",
    "obj = {\"slotName\":\"electricity_usage\",\"kind\":\"EXCEL\",\"ext\":\"xlsx\",\"period_start\":PERIOD_START,\"period_end\":PERIOD_END,\"dataframe\":df}\n",
    "print_full(validate_structured_upstream(obj, file_path=\"L1_dup_cols.xlsx\"))\n",
    "\n",
    "print(\"\\n=== [FAIL 기대] L1 - 빈 컬럼명 ===\")\n",
    "df = pd.DataFrame({\"\":[1]*10, \"B\":[2]*10})\n",
    "obj = {\"slotName\":\"electricity_usage\",\"kind\":\"EXCEL\",\"ext\":\"xlsx\",\"period_start\":PERIOD_START,\"period_end\":PERIOD_END,\"dataframe\":df}\n",
    "print_full(validate_structured_upstream(obj, file_path=\"L1_empty_col.xlsx\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436f09fa",
   "metadata": {},
   "source": [
    "Cell 16 — FAIL(L2) 필수 컬럼 탐지 실패\n",
    "역할\n",
    "\n",
    "L2에서 date/flow 후보를 못 찾으면 REQUIRED_FIELD_NOT_FOUND로 FAIL 나는지 증명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6769530f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== [FAIL 기대] L2 - REQUIRED_FIELD_NOT_FOUND ===\n",
      "[MAIN] start\n",
      "  - slotName: electricity_usage\n",
      "  - file_path: L2_required_not_found.xlsx\n",
      "[L0] PASS\n",
      "  - slotName: electricity_usage\n",
      "  - shape: (480, 3)\n",
      "  - period_start: 2026-02-01 00:00:00\n",
      "  - period_end: 2026-02-05 23:45:00\n",
      "[L1] PASS\n",
      "  - columns: ['비정상_날짜필드', '알수없는_수치', '메모']\n",
      "[L2] AUTO_LLM_TRIGGERED\n",
      "  - reason: rule_missing\n",
      "  - USE_LLM: False\n",
      "{\n",
      "  \"status\": \"FAIL\",\n",
      "  \"error\": {\n",
      "    \"code\": \"REQUIRED_FIELD_NOT_FOUND\",\n",
      "    \"message\": \"필수 컬럼(date/flow)을 찾지 못했습니다.\",\n",
      "    \"location\": \"columns\"\n",
      "  },\n",
      "  \"file_path\": \"L2_required_not_found.xlsx\",\n",
      "  \"processed_at\": \"2026-01-21T00:29:38Z\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 16: FAIL tests - L2 =====\n",
    "\n",
    "print(\"=== [FAIL 기대] L2 - REQUIRED_FIELD_NOT_FOUND ===\")\n",
    "df = pd.DataFrame({\n",
    "    \"비정상_날짜필드\": [\"x\"]*480,\n",
    "    \"알수없는_수치\": [\"foo\"]*480,\n",
    "    \"메모\": [\"memo\"]*480\n",
    "})\n",
    "obj = {\"slotName\":\"electricity_usage\",\"kind\":\"EXCEL\",\"ext\":\"xlsx\",\"period_start\":\"2026-02-01T00:00:00\",\"period_end\":\"2026-02-05T23:45:00\",\"dataframe\":df}\n",
    "print_full(validate_structured_upstream(obj, file_path=\"L2_required_not_found.xlsx\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e416d2",
   "metadata": {},
   "source": [
    "Cell 17 — FAIL(L3) 단위 불일치(전기인데 m3)\n",
    "역할\n",
    "\n",
    "L3에서 단위 mismatch가 제대로 FAIL 처리되는지 증명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f17872c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== [FAIL 기대] L3 - UNIT_MISMATCH ===\n",
      "[MAIN] start\n",
      "  - slotName: electricity_usage\n",
      "  - file_path: L3_unit_mismatch.xlsx\n",
      "[L0] PASS\n",
      "  - slotName: electricity_usage\n",
      "  - shape: (1344, 3)\n",
      "  - period_start: 2026-01-10 00:00:00\n",
      "  - period_end: 2026-01-23 23:45:00\n",
      "[L1] PASS\n",
      "  - columns: ['일시', '사용량(m3)', '비고']\n",
      "[L2] picked\n",
      "  - date_col: 일시\n",
      "  - flow_col: 사용량(m3)\n",
      "  - cum_col: None\n",
      "  - unit_cols: []\n",
      "{\n",
      "  \"status\": \"FAIL\",\n",
      "  \"error\": {\n",
      "    \"code\": \"UNIT_MISMATCH\",\n",
      "    \"message\": \"단위 불일치: got=m3, expected=kWh\",\n",
      "    \"location\": \"col:사용량(m3)\"\n",
      "  },\n",
      "  \"file_path\": \"L3_unit_mismatch.xlsx\",\n",
      "  \"processed_at\": \"2026-01-21T00:29:39Z\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 17: FAIL tests - L3 (UNIT_MISMATCH) =====\n",
    "\n",
    "print(\"=== [FAIL 기대] L3 - UNIT_MISMATCH ===\")\n",
    "ts = pd.date_range(\"2026-01-10 00:00:00\", \"2026-01-23 23:45:00\", freq=\"15min\")\n",
    "df = pd.DataFrame({\n",
    "    \"일시\": ts,\n",
    "    \"사용량(m3)\": np.round(np.random.uniform(10, 60, len(ts)), 3),  # 전기인데 m3로 들어온 케이스\n",
    "    \"비고\": [\"x\"]*len(ts)\n",
    "})\n",
    "obj = {\"slotName\":\"electricity_usage\",\"kind\":\"EXCEL\",\"ext\":\"xlsx\",\"period_start\":\"2026-01-10T00:00:00\",\"period_end\":\"2026-01-23T23:45:00\",\"dataframe\":df}\n",
    "print_full(validate_structured_upstream(obj, file_path=\"L3_unit_mismatch.xlsx\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8a804f",
   "metadata": {},
   "source": [
    "Cell 18 — FAIL(L4) 기간 내 timestamp 1개 누락\n",
    "역할\n",
    "\n",
    "L4에서 “기간 커버리지 100%”가 실제로 강제되는지 증명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "554fe7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== [FAIL 기대] L4 - PERIOD_MISSING_TIMESTAMPS ===\n",
      "[MAIN] start\n",
      "  - slotName: electricity_usage\n",
      "  - file_path: L4_missing_timestamp.xlsx\n",
      "[L0] PASS\n",
      "  - slotName: electricity_usage\n",
      "  - shape: (767, 3)\n",
      "  - period_start: 2026-01-24 00:00:00\n",
      "  - period_end: 2026-01-31 23:45:00\n",
      "[L1] PASS\n",
      "  - columns: ['일시', '사용량(kWh)', '역률']\n",
      "[L2] picked\n",
      "  - date_col: 일시\n",
      "  - flow_col: 사용량(kWh)\n",
      "  - cum_col: None\n",
      "  - unit_cols: ['사용량(kWh)']\n",
      "{\n",
      "  \"status\": \"FAIL\",\n",
      "  \"error\": {\n",
      "    \"code\": \"PERIOD_MISSING_TIMESTAMPS\",\n",
      "    \"message\": \"기간 내 timestamp 누락\",\n",
      "    \"location\": \"timestamp\"\n",
      "  },\n",
      "  \"file_path\": \"L4_missing_timestamp.xlsx\",\n",
      "  \"processed_at\": \"2026-01-21T00:29:40Z\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 18: FAIL tests - L4 (missing timestamp) =====\n",
    "\n",
    "print(\"=== [FAIL 기대] L4 - PERIOD_MISSING_TIMESTAMPS ===\")\n",
    "ps = \"2026-01-24T00:00:00\"\n",
    "pe = \"2026-01-31T23:45:00\"\n",
    "ts = pd.date_range(pd.to_datetime(ps), pd.to_datetime(pe), freq=\"15min\")\n",
    "df = pd.DataFrame({\n",
    "    \"일시\": ts,\n",
    "    \"사용량(kWh)\": np.round(np.random.uniform(50, 180, len(ts)), 3),\n",
    "    \"역률\": np.round(np.random.uniform(0.7, 1.0, len(ts)), 3),\n",
    "})\n",
    "df = df.drop(index=100).reset_index(drop=True)  # timestamp 1개 제거\n",
    "obj = {\"slotName\":\"electricity_usage\",\"kind\":\"EXCEL\",\"ext\":\"xlsx\",\"period_start\":ps,\"period_end\":pe,\"dataframe\":df}\n",
    "print_full(validate_structured_upstream(obj, file_path=\"L4_missing_timestamp.xlsx\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca5dca3",
   "metadata": {},
   "source": [
    "Cell 20 - 테스트용 셀 (19보다 먼저 실행)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e78200a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 20: LLM Stub/Spy utilities =====\n",
    "\n",
    "_LLM_ORIG_FUNCS = {}\n",
    "_LLM_STUB_INSTALLED = False\n",
    "_LLM_SPY_INSTALLED = False\n",
    "\n",
    "_LLM_CALL_COUNTER = {\"n\": 0}\n",
    "\n",
    "def llm_calls() -> int:\n",
    "    return int(_LLM_CALL_COUNTER[\"n\"])\n",
    "\n",
    "def reset_llm_calls():\n",
    "    _LLM_CALL_COUNTER[\"n\"] = 0\n",
    "\n",
    "def install_llm_stub(mapping: dict, llm_func_name: str = \"llm_classify_columns_min_tokens\"):\n",
    "    \"\"\"\n",
    "    llm_classify_columns_min_tokens를 스텁으로 바꿔서\n",
    "    항상 {\"mapping\": mapping}을 반환하게 함.\n",
    "    - mapping 예: {\"A\":\"date\",\"B\":\"flow\",\"C\":\"other\"}\n",
    "    \"\"\"\n",
    "    global _LLM_STUB_INSTALLED\n",
    "\n",
    "    if llm_func_name not in globals():\n",
    "        raise NameError(f\"{llm_func_name} is not defined in globals(). 먼저 Cell 7(LLM 함수) 정의를 확인하세요.\")\n",
    "\n",
    "    if llm_func_name not in _LLM_ORIG_FUNCS:\n",
    "        _LLM_ORIG_FUNCS[llm_func_name] = globals()[llm_func_name]\n",
    "\n",
    "    def _stub(columns, df, slotName):\n",
    "        _LLM_CALL_COUNTER[\"n\"] += 1\n",
    "        log(\"LLM_STUB\", \"CALLED\", n=_LLM_CALL_COUNTER[\"n\"], slotName=slotName, columns=len(columns))\n",
    "        # 스텁은 무조건 매핑만 반환(설명 문장 X)\n",
    "        return {\"mapping\": dict(mapping)}\n",
    "\n",
    "    globals()[llm_func_name] = _stub\n",
    "    _LLM_STUB_INSTALLED = True\n",
    "    print(\"LLM stub installed.\")\n",
    "\n",
    "def install_llm_spy(llm_func_name: str = \"llm_classify_columns_min_tokens\"):\n",
    "    \"\"\"\n",
    "    실제 llm_classify_columns_min_tokens 호출 횟수만 체크하는 spy.\n",
    "    (원본을 감싸서 counter만 증가)\n",
    "    \"\"\"\n",
    "    global _LLM_SPY_INSTALLED\n",
    "\n",
    "    if llm_func_name not in globals():\n",
    "        raise NameError(f\"{llm_func_name} is not defined in globals().\")\n",
    "\n",
    "    if llm_func_name not in _LLM_ORIG_FUNCS:\n",
    "        _LLM_ORIG_FUNCS[llm_func_name] = globals()[llm_func_name]\n",
    "\n",
    "    orig = _LLM_ORIG_FUNCS[llm_func_name]\n",
    "\n",
    "    def _spy(columns, df, slotName):\n",
    "        _LLM_CALL_COUNTER[\"n\"] += 1\n",
    "        log(\"LLM_SPY\", \"CALLED\", n=_LLM_CALL_COUNTER[\"n\"], slotName=slotName, columns=len(columns))\n",
    "        return orig(columns, df, slotName)\n",
    "\n",
    "    globals()[llm_func_name] = _spy\n",
    "    _LLM_SPY_INSTALLED = True\n",
    "    print(\"LLM spy installed.\")\n",
    "\n",
    "def restore_llm(llm_func_name: str = \"llm_classify_columns_min_tokens\"):\n",
    "    \"\"\"\n",
    "    stub/spy로 교체한 함수를 원복\n",
    "    \"\"\"\n",
    "    global _LLM_STUB_INSTALLED, _LLM_SPY_INSTALLED\n",
    "\n",
    "    if llm_func_name in _LLM_ORIG_FUNCS:\n",
    "        globals()[llm_func_name] = _LLM_ORIG_FUNCS[llm_func_name]\n",
    "        del _LLM_ORIG_FUNCS[llm_func_name]\n",
    "\n",
    "    _LLM_STUB_INSTALLED = False\n",
    "    _LLM_SPY_INSTALLED = False\n",
    "    print(\"Restored.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b8b47d",
   "metadata": {},
   "source": [
    "Cell 19 — LLM “호출 여부”를 확실히 증명하는 테스트(스파이/스텁 이용)\n",
    "역할\n",
    "\n",
    "팀원이 제일 많이 묻는 게 이거임:\n",
    "“LLM이 진짜 호출되긴 해?”\n",
    "\n",
    "이 셀은 force_llm=True로 LLM 경로를 강제로 태우고,\n",
    "Cell 20의 spy/stub 카운트로 ‘진짜 호출됐다’를 증명한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ef6128e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM stub installed.\n",
      "[L2] AUTO_LLM_TRIGGERED\n",
      "  - reason: rule_missing\n",
      "  - USE_LLM: True\n",
      "[LLM_STUB] CALLED\n",
      "  - n: 1\n",
      "  - slotName: electricity_usage\n",
      "  - columns: 3\n",
      "[L2] picked\n",
      "  - date_col: A\n",
      "  - flow_col: B\n",
      "  - cum_col: None\n",
      "  - unit_cols: []\n",
      "used_llm = True\n",
      "date_col = A\n",
      "flow_col = B\n",
      "LLM_CALLS = 1\n",
      "err2 = None\n",
      "Restored.\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 19: LLM call proof (NO force_llm param) =====\n",
    "\n",
    "reset_llm_calls()\n",
    "USE_LLM = True\n",
    "\n",
    "# 1) LLM이 항상 date/flow를 이렇게 찍도록 스텁 설치\n",
    "install_llm_stub(mapping={\"A\":\"date\", \"B\":\"flow\", \"C\":\"other\"}, llm_func_name=\"llm_classify_columns_min_tokens\")\n",
    "\n",
    "# 2) 룰/폴백이 못 맞추게: 컬럼명 A,B,C + 데이터도 일부러 애매하게(신호 부족)\n",
    "#    - A: 날짜처럼 보이지만 일부는 깨짐 -> dt_rate 낮게\n",
    "#    - B: 숫자처럼 보이지만 일부는 문자 -> num_rate 낮게\n",
    "ps = \"2026-02-01T00:00:00\"\n",
    "pe = \"2026-02-05T23:45:00\"\n",
    "ts = pd.date_range(pd.to_datetime(ps), pd.to_datetime(pe), freq=\"15min\")\n",
    "\n",
    "A = ts.astype(str).tolist()\n",
    "# 날짜 일부 깨기\n",
    "for i in np.random.choice(len(A), size=40, replace=False):\n",
    "    A[i] = \"날짜아님\"\n",
    "\n",
    "B = np.round(np.random.uniform(10, 60, len(ts)), 3).astype(object)\n",
    "# 숫자 일부 깨기\n",
    "for i in np.random.choice(len(B), size=40, replace=False):\n",
    "    B[i] = \"수치아님\"\n",
    "\n",
    "df = pd.DataFrame({\"A\": A, \"B\": B, \"C\": [\"memo\"]*len(ts)})\n",
    "\n",
    "# 3) L2 호출: 현재 너의 L2는 (rule 부족 && USE_LLM=True)면 LLM 호출함\n",
    "date_col, value_cols, unit_cols, err2, dbg = layer2_find_columns(df, slotName=\"electricity_usage\")\n",
    "\n",
    "print(\"used_llm =\", dbg.get(\"used_llm\"))\n",
    "print(\"date_col =\", date_col)\n",
    "print(\"flow_col =\", value_cols.get(\"flow\"))\n",
    "print(\"LLM_CALLS =\", llm_calls())\n",
    "print(\"err2 =\", err2)\n",
    "\n",
    "restore_llm()\n",
    "USE_LLM = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92251a5a",
   "metadata": {},
   "source": [
    "llm 최종 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "89ee6c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM stub installed.\n",
      "[MAIN] start\n",
      "  - slotName: electricity_usage\n",
      "  - file_path: LLM_FINAL_OUTPUT.xlsx\n",
      "[L0] PASS\n",
      "  - slotName: electricity_usage\n",
      "  - shape: (480, 3)\n",
      "  - period_start: 2026-02-01 00:00:00\n",
      "  - period_end: 2026-02-05 23:45:00\n",
      "[L1] PASS\n",
      "  - columns: ['A', 'B', 'C']\n",
      "[L2] AUTO_LLM_TRIGGERED\n",
      "  - reason: rule_missing\n",
      "  - USE_LLM: True\n",
      "[LLM_STUB] CALLED\n",
      "  - n: 1\n",
      "  - slotName: electricity_usage\n",
      "  - columns: 3\n",
      "[L2] picked\n",
      "  - date_col: A\n",
      "  - flow_col: B\n",
      "  - cum_col: None\n",
      "  - unit_cols: []\n",
      "[L4] PASS\n",
      "  - rows_in_period: 480\n",
      "{\n",
      "  \"status\": \"PASS\",\n",
      "  \"file_path\": \"LLM_FINAL_OUTPUT.xlsx\",\n",
      "  \"payload\": {\n",
      "    \"time_granularity\": \"15min\",\n",
      "    \"unit_schema\": [\n",
      "      \"time\",\n",
      "      \"kWh\",\n",
      "      \"-\"\n",
      "    ],\n",
      "    \"validated_fields\": [\n",
      "      \"timestamp\",\n",
      "      \"flow_kwh\",\n",
      "      \"C\"\n",
      "    ]\n",
      "  },\n",
      "  \"processed_at\": \"2026-01-21T00:38:44Z\"\n",
      "}\n",
      "LLM_CALLS = 1\n",
      "Restored.\n"
     ]
    }
   ],
   "source": [
    "# (1) Cell 20 먼저 실행된 상태여야 함\n",
    "reset_llm_calls()\n",
    "USE_LLM = True\n",
    "\n",
    "# (2) LLM이 date/flow를 강제로 찍게 stub\n",
    "install_llm_stub(mapping={\"A\":\"date\", \"B\":\"flow\", \"C\":\"other\"})\n",
    "\n",
    "# (3) 애매한 컬럼명 A/B/C + 값은 \"통과 가능하게\" 만든 df\n",
    "ps = \"2026-02-01T00:00:00\"\n",
    "pe = \"2026-02-05T23:45:00\"\n",
    "ts = pd.date_range(pd.to_datetime(ps), pd.to_datetime(pe), freq=\"15min\")\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"A\": ts,  # 날짜 신호 확실\n",
    "    \"B\": np.round(np.random.uniform(50, 180, len(ts)), 3),  # 숫자 신호 확실\n",
    "    \"C\": [\"memo\"] * len(ts)\n",
    "})\n",
    "\n",
    "obj = {\n",
    "    \"slotName\": \"electricity_usage\",\n",
    "    \"kind\": \"EXCEL\",\n",
    "    \"ext\": \"xlsx\",\n",
    "    \"period_start\": ps,\n",
    "    \"period_end\": pe,\n",
    "    \"dataframe\": df\n",
    "}\n",
    "\n",
    "res = validate_structured_upstream(obj, file_path=\"LLM_FINAL_OUTPUT.xlsx\")\n",
    "print_full(res)\n",
    "\n",
    "print(\"LLM_CALLS =\", llm_calls())\n",
    "\n",
    "restore_llm()\n",
    "USE_LLM = False\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
